// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: mediapipe/modules/face_geometry/protos/face_geometry.proto

package com.google.mediapipe.modules.facegeometry;

public final class FaceGeometryProto {
    private FaceGeometryProto() {}
    public static void registerAllExtensions(
            com.google.protobuf.ExtensionRegistryLite registry) {
    }
    public interface FaceGeometryOrBuilder extends
            // @@protoc_insertion_point(interface_extends:mediapipe.face_geometry.FaceGeometry)
            com.google.protobuf.MessageLiteOrBuilder {

        /**
         * <pre>
         * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
         * the face landmark IDs.
         * XYZ coordinates exist in the right-handed Metric 3D space configured by an
         * environment. UV coodinates are taken from the canonical face mesh model.
         * XY coordinates are guaranteed to match the screen positions of
         * the input face landmarks after (1) being multiplied by the face pose
         * transformation matrix and then (2) being projected with a perspective
         * camera matrix of the same environment.
         * </pre>
         *
         * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
         * @return Whether the mesh field is set.
         */
        boolean hasMesh();
        /**
         * <pre>
         * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
         * the face landmark IDs.
         * XYZ coordinates exist in the right-handed Metric 3D space configured by an
         * environment. UV coodinates are taken from the canonical face mesh model.
         * XY coordinates are guaranteed to match the screen positions of
         * the input face landmarks after (1) being multiplied by the face pose
         * transformation matrix and then (2) being projected with a perspective
         * camera matrix of the same environment.
         * </pre>
         *
         * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
         * @return The mesh.
         */
        com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d getMesh();

        /**
         * <pre>
         * Defines a face pose transformation matrix, which provides mapping from
         * the static canonical face model to the runtime face. Tries to distinguish
         * a head pose change from a facial expression change and to only reflect the
         * former.
         * Is a 4x4 matrix and contains only the following components:
         *   * Uniform scale
         *   * Rotation
         *   * Translation
         * The last row is guaranteed to be `[0 0 0 1]`.
         * </pre>
         *
         * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
         * @return Whether the poseTransformMatrix field is set.
         */
        boolean hasPoseTransformMatrix();
        /**
         * <pre>
         * Defines a face pose transformation matrix, which provides mapping from
         * the static canonical face model to the runtime face. Tries to distinguish
         * a head pose change from a facial expression change and to only reflect the
         * former.
         * Is a 4x4 matrix and contains only the following components:
         *   * Uniform scale
         *   * Rotation
         *   * Translation
         * The last row is guaranteed to be `[0 0 0 1]`.
         * </pre>
         *
         * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
         * @return The poseTransformMatrix.
         */
        com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData getPoseTransformMatrix();
    }
    /**
     * <pre>
     * Defines the face geometry pipeline estimation result format.
     * </pre>
     *
     * Protobuf type {@code mediapipe.face_geometry.FaceGeometry}
     */
    public  static final class FaceGeometry extends
            com.google.protobuf.GeneratedMessageLite<
                    FaceGeometry, FaceGeometry.Builder> implements
            // @@protoc_insertion_point(message_implements:mediapipe.face_geometry.FaceGeometry)
            FaceGeometryOrBuilder {
        private FaceGeometry() {
        }
        private int bitField0_;
        public static final int MESH_FIELD_NUMBER = 1;
        private com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d mesh_;
        /**
         * <pre>
         * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
         * the face landmark IDs.
         * XYZ coordinates exist in the right-handed Metric 3D space configured by an
         * environment. UV coodinates are taken from the canonical face mesh model.
         * XY coordinates are guaranteed to match the screen positions of
         * the input face landmarks after (1) being multiplied by the face pose
         * transformation matrix and then (2) being projected with a perspective
         * camera matrix of the same environment.
         * </pre>
         *
         * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
         */
        @java.lang.Override
        public boolean hasMesh() {
            return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <pre>
         * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
         * the face landmark IDs.
         * XYZ coordinates exist in the right-handed Metric 3D space configured by an
         * environment. UV coodinates are taken from the canonical face mesh model.
         * XY coordinates are guaranteed to match the screen positions of
         * the input face landmarks after (1) being multiplied by the face pose
         * transformation matrix and then (2) being projected with a perspective
         * camera matrix of the same environment.
         * </pre>
         *
         * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
         */
        @java.lang.Override
        public com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d getMesh() {
            return mesh_ == null ? com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d.getDefaultInstance() : mesh_;
        }
        /**
         * <pre>
         * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
         * the face landmark IDs.
         * XYZ coordinates exist in the right-handed Metric 3D space configured by an
         * environment. UV coodinates are taken from the canonical face mesh model.
         * XY coordinates are guaranteed to match the screen positions of
         * the input face landmarks after (1) being multiplied by the face pose
         * transformation matrix and then (2) being projected with a perspective
         * camera matrix of the same environment.
         * </pre>
         *
         * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
         */
        private void setMesh(com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d value) {
            value.getClass();
            mesh_ = value;
            bitField0_ |= 0x00000001;
        }
        /**
         * <pre>
         * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
         * the face landmark IDs.
         * XYZ coordinates exist in the right-handed Metric 3D space configured by an
         * environment. UV coodinates are taken from the canonical face mesh model.
         * XY coordinates are guaranteed to match the screen positions of
         * the input face landmarks after (1) being multiplied by the face pose
         * transformation matrix and then (2) being projected with a perspective
         * camera matrix of the same environment.
         * </pre>
         *
         * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
         */
        @java.lang.SuppressWarnings({"ReferenceEquality"})
        private void mergeMesh(com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d value) {
            value.getClass();
            if (mesh_ != null &&
                    mesh_ != com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d.getDefaultInstance()) {
                mesh_ =
                        com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d.newBuilder(mesh_).mergeFrom(value).buildPartial();
            } else {
                mesh_ = value;
            }
            bitField0_ |= 0x00000001;
        }
        /**
         * <pre>
         * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
         * the face landmark IDs.
         * XYZ coordinates exist in the right-handed Metric 3D space configured by an
         * environment. UV coodinates are taken from the canonical face mesh model.
         * XY coordinates are guaranteed to match the screen positions of
         * the input face landmarks after (1) being multiplied by the face pose
         * transformation matrix and then (2) being projected with a perspective
         * camera matrix of the same environment.
         * </pre>
         *
         * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
         */
        private void clearMesh() {  mesh_ = null;
            bitField0_ = (bitField0_ & ~0x00000001);
        }

        public static final int POSE_TRANSFORM_MATRIX_FIELD_NUMBER = 2;
        private com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData poseTransformMatrix_;
        /**
         * <pre>
         * Defines a face pose transformation matrix, which provides mapping from
         * the static canonical face model to the runtime face. Tries to distinguish
         * a head pose change from a facial expression change and to only reflect the
         * former.
         * Is a 4x4 matrix and contains only the following components:
         *   * Uniform scale
         *   * Rotation
         *   * Translation
         * The last row is guaranteed to be `[0 0 0 1]`.
         * </pre>
         *
         * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
         */
        @java.lang.Override
        public boolean hasPoseTransformMatrix() {
            return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <pre>
         * Defines a face pose transformation matrix, which provides mapping from
         * the static canonical face model to the runtime face. Tries to distinguish
         * a head pose change from a facial expression change and to only reflect the
         * former.
         * Is a 4x4 matrix and contains only the following components:
         *   * Uniform scale
         *   * Rotation
         *   * Translation
         * The last row is guaranteed to be `[0 0 0 1]`.
         * </pre>
         *
         * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
         */
        @java.lang.Override
        public com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData getPoseTransformMatrix() {
            return poseTransformMatrix_ == null ? com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData.getDefaultInstance() : poseTransformMatrix_;
        }
        /**
         * <pre>
         * Defines a face pose transformation matrix, which provides mapping from
         * the static canonical face model to the runtime face. Tries to distinguish
         * a head pose change from a facial expression change and to only reflect the
         * former.
         * Is a 4x4 matrix and contains only the following components:
         *   * Uniform scale
         *   * Rotation
         *   * Translation
         * The last row is guaranteed to be `[0 0 0 1]`.
         * </pre>
         *
         * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
         */
        private void setPoseTransformMatrix(com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData value) {
            value.getClass();
            poseTransformMatrix_ = value;
            bitField0_ |= 0x00000002;
        }
        /**
         * <pre>
         * Defines a face pose transformation matrix, which provides mapping from
         * the static canonical face model to the runtime face. Tries to distinguish
         * a head pose change from a facial expression change and to only reflect the
         * former.
         * Is a 4x4 matrix and contains only the following components:
         *   * Uniform scale
         *   * Rotation
         *   * Translation
         * The last row is guaranteed to be `[0 0 0 1]`.
         * </pre>
         *
         * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
         */
        @java.lang.SuppressWarnings({"ReferenceEquality"})
        private void mergePoseTransformMatrix(com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData value) {
            value.getClass();
            if (poseTransformMatrix_ != null &&
                    poseTransformMatrix_ != com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData.getDefaultInstance()) {
                poseTransformMatrix_ =
                        com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData.newBuilder(poseTransformMatrix_).mergeFrom(value).buildPartial();
            } else {
                poseTransformMatrix_ = value;
            }
            bitField0_ |= 0x00000002;
        }
        /**
         * <pre>
         * Defines a face pose transformation matrix, which provides mapping from
         * the static canonical face model to the runtime face. Tries to distinguish
         * a head pose change from a facial expression change and to only reflect the
         * former.
         * Is a 4x4 matrix and contains only the following components:
         *   * Uniform scale
         *   * Rotation
         *   * Translation
         * The last row is guaranteed to be `[0 0 0 1]`.
         * </pre>
         *
         * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
         */
        private void clearPoseTransformMatrix() {  poseTransformMatrix_ = null;
            bitField0_ = (bitField0_ & ~0x00000002);
        }

        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(
                java.nio.ByteBuffer data)
                throws com.google.protobuf.InvalidProtocolBufferException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, data);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(
                java.nio.ByteBuffer data,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws com.google.protobuf.InvalidProtocolBufferException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, data, extensionRegistry);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(
                com.google.protobuf.ByteString data)
                throws com.google.protobuf.InvalidProtocolBufferException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, data);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(
                com.google.protobuf.ByteString data,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws com.google.protobuf.InvalidProtocolBufferException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, data, extensionRegistry);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(byte[] data)
                throws com.google.protobuf.InvalidProtocolBufferException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, data);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(
                byte[] data,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws com.google.protobuf.InvalidProtocolBufferException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, data, extensionRegistry);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(java.io.InputStream input)
                throws java.io.IOException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, input);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(
                java.io.InputStream input,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws java.io.IOException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, input, extensionRegistry);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseDelimitedFrom(java.io.InputStream input)
                throws java.io.IOException {
            return parseDelimitedFrom(DEFAULT_INSTANCE, input);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseDelimitedFrom(
                java.io.InputStream input,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws java.io.IOException {
            return parseDelimitedFrom(DEFAULT_INSTANCE, input, extensionRegistry);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(
                com.google.protobuf.CodedInputStream input)
                throws java.io.IOException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, input);
        }
        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry parseFrom(
                com.google.protobuf.CodedInputStream input,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws java.io.IOException {
            return com.google.protobuf.GeneratedMessageLite.parseFrom(
                    DEFAULT_INSTANCE, input, extensionRegistry);
        }

        public static Builder newBuilder() {
            return (Builder) DEFAULT_INSTANCE.createBuilder();
        }
        public static Builder newBuilder(com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry prototype) {
            return (Builder) DEFAULT_INSTANCE.createBuilder(prototype);
        }

        /**
         * <pre>
         * Defines the face geometry pipeline estimation result format.
         * </pre>
         *
         * Protobuf type {@code mediapipe.face_geometry.FaceGeometry}
         */
        public static final class Builder extends
                com.google.protobuf.GeneratedMessageLite.Builder<
                        com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry, Builder> implements
                // @@protoc_insertion_point(builder_implements:mediapipe.face_geometry.FaceGeometry)
                com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometryOrBuilder {
            // Construct using com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry.newBuilder()
            private Builder() {
                super(DEFAULT_INSTANCE);
            }


            /**
             * <pre>
             * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
             * the face landmark IDs.
             * XYZ coordinates exist in the right-handed Metric 3D space configured by an
             * environment. UV coodinates are taken from the canonical face mesh model.
             * XY coordinates are guaranteed to match the screen positions of
             * the input face landmarks after (1) being multiplied by the face pose
             * transformation matrix and then (2) being projected with a perspective
             * camera matrix of the same environment.
             * </pre>
             *
             * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
             */
            @java.lang.Override
            public boolean hasMesh() {
                return instance.hasMesh();
            }
            /**
             * <pre>
             * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
             * the face landmark IDs.
             * XYZ coordinates exist in the right-handed Metric 3D space configured by an
             * environment. UV coodinates are taken from the canonical face mesh model.
             * XY coordinates are guaranteed to match the screen positions of
             * the input face landmarks after (1) being multiplied by the face pose
             * transformation matrix and then (2) being projected with a perspective
             * camera matrix of the same environment.
             * </pre>
             *
             * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
             */
            @java.lang.Override
            public com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d getMesh() {
                return instance.getMesh();
            }
            /**
             * <pre>
             * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
             * the face landmark IDs.
             * XYZ coordinates exist in the right-handed Metric 3D space configured by an
             * environment. UV coodinates are taken from the canonical face mesh model.
             * XY coordinates are guaranteed to match the screen positions of
             * the input face landmarks after (1) being multiplied by the face pose
             * transformation matrix and then (2) being projected with a perspective
             * camera matrix of the same environment.
             * </pre>
             *
             * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
             */
            public Builder setMesh(com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d value) {
                copyOnWrite();
                instance.setMesh(value);
                return this;
            }
            /**
             * <pre>
             * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
             * the face landmark IDs.
             * XYZ coordinates exist in the right-handed Metric 3D space configured by an
             * environment. UV coodinates are taken from the canonical face mesh model.
             * XY coordinates are guaranteed to match the screen positions of
             * the input face landmarks after (1) being multiplied by the face pose
             * transformation matrix and then (2) being projected with a perspective
             * camera matrix of the same environment.
             * </pre>
             *
             * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
             */
            public Builder setMesh(
                    com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d.Builder builderForValue) {
                copyOnWrite();
                instance.setMesh(builderForValue.build());
                return this;
            }
            /**
             * <pre>
             * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
             * the face landmark IDs.
             * XYZ coordinates exist in the right-handed Metric 3D space configured by an
             * environment. UV coodinates are taken from the canonical face mesh model.
             * XY coordinates are guaranteed to match the screen positions of
             * the input face landmarks after (1) being multiplied by the face pose
             * transformation matrix and then (2) being projected with a perspective
             * camera matrix of the same environment.
             * </pre>
             *
             * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
             */
            public Builder mergeMesh(com.google.mediapipe.modules.facegeometry.Mesh3dProto.Mesh3d value) {
                copyOnWrite();
                instance.mergeMesh(value);
                return this;
            }
            /**
             * <pre>
             * Defines a mesh surface for a face. The face mesh vertex IDs are the same as
             * the face landmark IDs.
             * XYZ coordinates exist in the right-handed Metric 3D space configured by an
             * environment. UV coodinates are taken from the canonical face mesh model.
             * XY coordinates are guaranteed to match the screen positions of
             * the input face landmarks after (1) being multiplied by the face pose
             * transformation matrix and then (2) being projected with a perspective
             * camera matrix of the same environment.
             * </pre>
             *
             * <code>optional .mediapipe.face_geometry.Mesh3d mesh = 1;</code>
             */
            public Builder clearMesh() {  copyOnWrite();
                instance.clearMesh();
                return this;
            }

            /**
             * <pre>
             * Defines a face pose transformation matrix, which provides mapping from
             * the static canonical face model to the runtime face. Tries to distinguish
             * a head pose change from a facial expression change and to only reflect the
             * former.
             * Is a 4x4 matrix and contains only the following components:
             *   * Uniform scale
             *   * Rotation
             *   * Translation
             * The last row is guaranteed to be `[0 0 0 1]`.
             * </pre>
             *
             * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
             */
            @java.lang.Override
            public boolean hasPoseTransformMatrix() {
                return instance.hasPoseTransformMatrix();
            }
            /**
             * <pre>
             * Defines a face pose transformation matrix, which provides mapping from
             * the static canonical face model to the runtime face. Tries to distinguish
             * a head pose change from a facial expression change and to only reflect the
             * former.
             * Is a 4x4 matrix and contains only the following components:
             *   * Uniform scale
             *   * Rotation
             *   * Translation
             * The last row is guaranteed to be `[0 0 0 1]`.
             * </pre>
             *
             * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
             */
            @java.lang.Override
            public com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData getPoseTransformMatrix() {
                return instance.getPoseTransformMatrix();
            }
            /**
             * <pre>
             * Defines a face pose transformation matrix, which provides mapping from
             * the static canonical face model to the runtime face. Tries to distinguish
             * a head pose change from a facial expression change and to only reflect the
             * former.
             * Is a 4x4 matrix and contains only the following components:
             *   * Uniform scale
             *   * Rotation
             *   * Translation
             * The last row is guaranteed to be `[0 0 0 1]`.
             * </pre>
             *
             * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
             */
            public Builder setPoseTransformMatrix(com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData value) {
                copyOnWrite();
                instance.setPoseTransformMatrix(value);
                return this;
            }
            /**
             * <pre>
             * Defines a face pose transformation matrix, which provides mapping from
             * the static canonical face model to the runtime face. Tries to distinguish
             * a head pose change from a facial expression change and to only reflect the
             * former.
             * Is a 4x4 matrix and contains only the following components:
             *   * Uniform scale
             *   * Rotation
             *   * Translation
             * The last row is guaranteed to be `[0 0 0 1]`.
             * </pre>
             *
             * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
             */
            public Builder setPoseTransformMatrix(
                    com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData.Builder builderForValue) {
                copyOnWrite();
                instance.setPoseTransformMatrix(builderForValue.build());
                return this;
            }
            /**
             * <pre>
             * Defines a face pose transformation matrix, which provides mapping from
             * the static canonical face model to the runtime face. Tries to distinguish
             * a head pose change from a facial expression change and to only reflect the
             * former.
             * Is a 4x4 matrix and contains only the following components:
             *   * Uniform scale
             *   * Rotation
             *   * Translation
             * The last row is guaranteed to be `[0 0 0 1]`.
             * </pre>
             *
             * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
             */
            public Builder mergePoseTransformMatrix(com.google.mediapipe.formats.proto.MatrixDataProto.MatrixData value) {
                copyOnWrite();
                instance.mergePoseTransformMatrix(value);
                return this;
            }
            /**
             * <pre>
             * Defines a face pose transformation matrix, which provides mapping from
             * the static canonical face model to the runtime face. Tries to distinguish
             * a head pose change from a facial expression change and to only reflect the
             * former.
             * Is a 4x4 matrix and contains only the following components:
             *   * Uniform scale
             *   * Rotation
             *   * Translation
             * The last row is guaranteed to be `[0 0 0 1]`.
             * </pre>
             *
             * <code>optional .mediapipe.MatrixData pose_transform_matrix = 2;</code>
             */
            public Builder clearPoseTransformMatrix() {  copyOnWrite();
                instance.clearPoseTransformMatrix();
                return this;
            }

            // @@protoc_insertion_point(builder_scope:mediapipe.face_geometry.FaceGeometry)
        }
        @java.lang.Override
        @java.lang.SuppressWarnings({"unchecked", "fallthrough"})
        protected final java.lang.Object dynamicMethod(
                com.google.protobuf.GeneratedMessageLite.MethodToInvoke method,
                java.lang.Object arg0, java.lang.Object arg1) {
            switch (method) {
                case NEW_MUTABLE_INSTANCE: {
                    return new com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry();
                }
                case NEW_BUILDER: {
                    return new Builder();
                }
                case BUILD_MESSAGE_INFO: {
                    java.lang.Object[] objects = new java.lang.Object[] {
                            "bitField0_",
                            "mesh_",
                            "poseTransformMatrix_",
                    };
                    java.lang.String info =
                            "\u0001\u0002\u0000\u0001\u0001\u0002\u0002\u0000\u0000\u0000\u0001\t\u0000\u0002" +
                                    "\t\u0001";
                    return newMessageInfo(DEFAULT_INSTANCE, info, objects);
                }
                // fall through
                case GET_DEFAULT_INSTANCE: {
                    return DEFAULT_INSTANCE;
                }
                case GET_PARSER: {
                    com.google.protobuf.Parser<com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry> parser = PARSER;
                    if (parser == null) {
                        synchronized (com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry.class) {
                            parser = PARSER;
                            if (parser == null) {
                                parser =
                                        new DefaultInstanceBasedParser<com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry>(
                                                DEFAULT_INSTANCE);
                                PARSER = parser;
                            }
                        }
                    }
                    return parser;
                }
                case GET_MEMOIZED_IS_INITIALIZED: {
                    return (byte) 1;
                }
                case SET_MEMOIZED_IS_INITIALIZED: {
                    return null;
                }
            }
            throw new UnsupportedOperationException();
        }


        // @@protoc_insertion_point(class_scope:mediapipe.face_geometry.FaceGeometry)
        private static final com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry DEFAULT_INSTANCE;
        static {
            FaceGeometry defaultInstance = new FaceGeometry();
            // New instances are implicitly immutable so no need to make
            // immutable.
            DEFAULT_INSTANCE = defaultInstance;
            com.google.protobuf.GeneratedMessageLite.registerDefaultInstance(
                    FaceGeometry.class, defaultInstance);
        }

        public static com.google.mediapipe.modules.facegeometry.FaceGeometryProto.FaceGeometry getDefaultInstance() {
            return DEFAULT_INSTANCE;
        }

        private static volatile com.google.protobuf.Parser<FaceGeometry> PARSER;

        public static com.google.protobuf.Parser<FaceGeometry> parser() {
            return DEFAULT_INSTANCE.getParserForType();
        }
    }


    static {
    }

    // @@protoc_insertion_point(outer_class_scope)
}
